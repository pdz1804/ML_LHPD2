{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3117_Machine_Learning\\Main\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute path to the 'src' directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.features.build_features_utils import *  # Assuming build_features_utils is inside build_features.py\n",
    "from src.models.models_utils import *  # Assuming utils.py exists inside src/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state to match training (if applicable)\n",
    "random_state = 42\n",
    "\n",
    "# Load the data (make sure to load your df_sampled or similar dataset)\n",
    "dataset_path = os.path.join(project_root, \"data\", \"final\", \"final_clean_no_neutral_no_duplicates.csv\")\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Replace target 4 with 1\n",
    "df[\"target\"] = df[\"target\"].replace(4, 1)\n",
    "\n",
    "df_sampled = df.sample(n=1000, random_state=42)\n",
    "\n",
    "# Split the data as done during training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled[\"text_clean\"], df_sampled[\"target\"], test_size=0.2, random_state=random_state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 800\n",
      "Test set size: 200\n",
      "Training labels size: 800\n",
      "Test labels size: 200\n"
     ]
    }
   ],
   "source": [
    "# Print lengths of splits\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training labels size: {len(y_train)}\")\n",
    "print(f\"Test labels size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature methods\n",
    "feature_methods = [\"tfidf\", \"count\", \"word2vec\", \"glove\"]\n",
    "\n",
    "X_test_features_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tfidf - X_test_features shape: (200, 2000)\n",
      "✅ count - X_test_features shape: (200, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Word2Vec: 100%|██████████| 200/200 [00:00<00:00, 18891.98document/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ word2vec - X_test_features shape: (200, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GloVe: 100%|██████████| 200/200 [00:00<00:00, 4847.93document/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ glove - X_test_features shape: (200, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict for each model\n",
    "for method in feature_methods:\n",
    "    # Initialize FeatureBuilder\n",
    "    feature_builder = FeatureBuilder(\n",
    "        method=method,\n",
    "        save_dir=os.path.join(project_root, \"data\", \"processed\"),\n",
    "        reduce_dim=None,  # Assuming you want to reduce dimensions using PCA\n",
    "        n_components=50\n",
    "    )\n",
    "\n",
    "    # Transform test data\n",
    "    feature_builder.fit(X_train.tolist())\n",
    "    X_test_features_dict[method] = feature_builder.transform(X_test.tolist())\n",
    "    print(f\"✅ {method} - X_test_features shape: {X_test_features_dict[method].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"decision_tree\", \"logistic_regression\", \"random_forest\", \"xgboost\", \"perceptron\", \"bayesian_enhanced\", \"svm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: decision_tree\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5050\n",
      "Precision: 0.5029\n",
      "Recall: 0.8700\n",
      "F1 Score: 0.6374\n",
      "ROC AUC: 0.5162\n",
      "--------------------------------------------------\n",
      "Model: decision_tree\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5700\n",
      "Precision: 0.7500\n",
      "Recall: 0.2100\n",
      "F1 Score: 0.3281\n",
      "ROC AUC: 0.5737\n",
      "--------------------------------------------------\n",
      "Model: decision_tree\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5800\n",
      "Precision: 0.5784\n",
      "Recall: 0.5900\n",
      "F1 Score: 0.5842\n",
      "ROC AUC: 0.6092\n",
      "--------------------------------------------------\n",
      "Model: decision_tree\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5450\n",
      "Precision: 0.5506\n",
      "Recall: 0.4900\n",
      "F1 Score: 0.5185\n",
      "ROC AUC: 0.5495\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: logistic_regression\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6250\n",
      "Precision: 0.6147\n",
      "Recall: 0.6700\n",
      "F1 Score: 0.6411\n",
      "ROC AUC: 0.6799\n",
      "--------------------------------------------------\n",
      "Model: logistic_regression\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6450\n",
      "Precision: 0.6283\n",
      "Recall: 0.7100\n",
      "F1 Score: 0.6667\n",
      "ROC AUC: 0.6860\n",
      "--------------------------------------------------\n",
      "Model: logistic_regression\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6950\n",
      "Precision: 0.6857\n",
      "Recall: 0.7200\n",
      "F1 Score: 0.7024\n",
      "ROC AUC: 0.7832\n",
      "--------------------------------------------------\n",
      "Model: logistic_regression\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6650\n",
      "Precision: 0.6410\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.6912\n",
      "ROC AUC: 0.7248\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: random_forest\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5700\n",
      "Precision: 0.5486\n",
      "Recall: 0.7900\n",
      "F1 Score: 0.6475\n",
      "ROC AUC: 0.6522\n",
      "--------------------------------------------------\n",
      "Model: random_forest\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5900\n",
      "Precision: 0.5682\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.6466\n",
      "ROC AUC: 0.6606\n",
      "--------------------------------------------------\n",
      "Model: random_forest\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6850\n",
      "Precision: 0.6832\n",
      "Recall: 0.6900\n",
      "F1 Score: 0.6866\n",
      "ROC AUC: 0.7362\n",
      "--------------------------------------------------\n",
      "Model: random_forest\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6350\n",
      "Precision: 0.6174\n",
      "Recall: 0.7100\n",
      "F1 Score: 0.6605\n",
      "ROC AUC: 0.6641\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: xgboost\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5450\n",
      "Precision: 0.5349\n",
      "Recall: 0.6900\n",
      "F1 Score: 0.6026\n",
      "ROC AUC: 0.6046\n",
      "--------------------------------------------------\n",
      "Model: xgboost\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5750\n",
      "Precision: 0.5620\n",
      "Recall: 0.6800\n",
      "F1 Score: 0.6154\n",
      "ROC AUC: 0.6262\n",
      "--------------------------------------------------\n",
      "Model: xgboost\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6400\n",
      "Precision: 0.6400\n",
      "Recall: 0.6400\n",
      "F1 Score: 0.6400\n",
      "ROC AUC: 0.7355\n",
      "--------------------------------------------------\n",
      "Model: xgboost\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6400\n",
      "Precision: 0.6250\n",
      "Recall: 0.7000\n",
      "F1 Score: 0.6604\n",
      "ROC AUC: 0.6671\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: perceptron\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6150\n",
      "Precision: 0.6420\n",
      "Recall: 0.5200\n",
      "F1 Score: 0.5746\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: perceptron\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6300\n",
      "Precision: 0.6806\n",
      "Recall: 0.4900\n",
      "F1 Score: 0.5698\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: perceptron\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6200\n",
      "Precision: 0.8750\n",
      "Recall: 0.2800\n",
      "F1 Score: 0.4242\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: perceptron\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5200\n",
      "Precision: 1.0000\n",
      "Recall: 0.0400\n",
      "F1 Score: 0.0769\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: bayesian_enhanced\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5900\n",
      "Precision: 0.6875\n",
      "Recall: 0.3300\n",
      "F1 Score: 0.4459\n",
      "ROC AUC: 0.6072\n",
      "--------------------------------------------------\n",
      "Model: bayesian_enhanced\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5950\n",
      "Precision: 0.7021\n",
      "Recall: 0.3300\n",
      "F1 Score: 0.4490\n",
      "ROC AUC: 0.6272\n",
      "--------------------------------------------------\n",
      "Model: bayesian_enhanced\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6250\n",
      "Precision: 0.7273\n",
      "Recall: 0.4000\n",
      "F1 Score: 0.5161\n",
      "ROC AUC: 0.6781\n",
      "--------------------------------------------------\n",
      "Model: bayesian_enhanced\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5950\n",
      "Precision: 0.6462\n",
      "Recall: 0.4200\n",
      "F1 Score: 0.5091\n",
      "ROC AUC: 0.6470\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Model: svm\n",
      "Method: tfidf\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.6667\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: svm\n",
      "Method: count\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6150\n",
      "Precision: 0.5966\n",
      "Recall: 0.7100\n",
      "F1 Score: 0.6484\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: svm\n",
      "Method: word2vec\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6800\n",
      "Precision: 0.6406\n",
      "Recall: 0.8200\n",
      "F1 Score: 0.7193\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "Model: svm\n",
      "Method: glove\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.6950\n",
      "Precision: 0.6789\n",
      "Recall: 0.7400\n",
      "F1 Score: 0.7081\n",
      "ROC AUC: N/A\n",
      "--------------------------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "# Predict for each model\n",
    "for model_name in model_names:\n",
    "    for method in feature_methods:\n",
    "        # Load the saved model\n",
    "        model_filename = os.path.join(project_root, \"src\", \"models\", f\"best_{model_name}_{method}.pkl\")\n",
    "        with open(model_filename, 'rb') as model_file:\n",
    "            model = joblib.load(model_file)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_features_dict[method])\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='binary')\n",
    "        recall = recall_score(y_test, y_pred, average='binary')\n",
    "        f1 = f1_score(y_test, y_pred, average='binary')\n",
    "        \n",
    "        # ROC AUC can be computed if the model outputs probabilities\n",
    "        # Handle models that do not support `predict_proba`\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test_features_dict[method])[:, 1]  # Take the positive class probabilities\n",
    "            roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        else:\n",
    "            roc_auc = \"N/A\"  # Not applicable for models like Perceptron\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Method: {method}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(\"ROC AUC: N/A\")\n",
    "        print(\"-\" * 50)\n",
    "    print(\"%\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
