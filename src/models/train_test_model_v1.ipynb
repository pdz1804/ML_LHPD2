{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras-tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (3.13.0)\n",
      "Requirement already satisfied: optree in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests->keras-tuner) (2024.12.14)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hmmlearn in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (0.3.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.10 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from hmmlearn) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from hmmlearn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=0.19 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from hmmlearn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
      "Requirement already satisfied: pgmpy in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (0.1.26)\n",
      "Requirement already satisfied: networkx in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (3.4.2)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (1.5.2)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (2.2.3)\n",
      "Requirement already satisfied: pyparsing in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (3.2.0)\n",
      "Requirement already satisfied: torch in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (2.5.1)\n",
      "Requirement already satisfied: statsmodels in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (0.14.4)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (4.66.5)\n",
      "Requirement already satisfied: joblib in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (1.4.2)\n",
      "Requirement already satisfied: opt-einsum in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (3.4.0)\n",
      "Requirement already satisfied: xgboost in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (2.1.1)\n",
      "Requirement already satisfied: google-generativeai in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pgmpy) (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (2.161.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (2.38.0)\n",
      "Requirement already satisfied: protobuf in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (5.29.3)\n",
      "Requirement already satisfied: pydantic in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-generativeai->pgmpy) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pgmpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pandas->pgmpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pandas->pgmpy) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from scikit-learn->pgmpy) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from statsmodels->pgmpy) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels->pgmpy) (24.2)\n",
      "Requirement already satisfied: filelock in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from torch->pgmpy) (3.13.1)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from torch->pgmpy) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from torch->pgmpy) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from torch->pgmpy) (3.1.5)\n",
      "Requirement already satisfied: fsspec in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from torch->pgmpy) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->pgmpy) (0.4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-core->google-generativeai->pgmpy) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from jinja2->torch->pgmpy) (2.1.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pydantic->google-generativeai->pgmpy) (2.27.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy) (1.70.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\ml_env_2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install hmmlearn\n",
    "%pip install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import hmmlearn.hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import log_loss, hinge_loss, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\ml_env_2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Options\n",
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3117_Machine_Learning\\Main\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute path to the 'src' directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.features.build_features_utils import *  # Assuming build_features_utils is inside build_features.py\n",
    "from src.models.models_utils import *  # Assuming utils.py exists inside src/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for models\n",
    "MODEL_DICT = {\n",
    "    \"decision_tree\": DecisionTreeClassifier,\n",
    "    \"perceptron\": Perceptron,\n",
    "    \"mlp\": MLPClassifier,\n",
    "    \"bayesian\": GaussianNB,\n",
    "    \"random_forest\": RandomForestClassifier,\n",
    "    \"xgboost\": xgb.XGBClassifier,\n",
    "    \"svm\": SVC,\n",
    "    \"logistic_regression\": LogisticRegression,\n",
    "    \"hmm\": lambda: hmmlearn.hmm.GaussianHMM(n_components=3),\n",
    "    \"crf\": lambda: CRF(\n",
    "        algorithm=\"lbfgs\",  \n",
    "        max_iterations=100,  \n",
    "        all_possible_transitions=True # not tested yet\n",
    "    ),\n",
    "    \"bayes_network\": BayesianNetworkClassifier, # Loc defined\n",
    "} \n",
    "\n",
    "# Dictionary for model parameters\n",
    "MODEL_PARAMS = {\n",
    "    # \"decision_tree\": {\n",
    "    #     \"criterion\": [\"gini\", \"entropy\"],\n",
    "    #     \"max_depth\": [10, 20],\n",
    "    #     \"min_samples_split\": [2, 5],\n",
    "    #     \"min_samples_leaf\": [1, 2],\n",
    "    #     \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    # },\n",
    "    \n",
    "    \"decision_tree\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [10, 20, 30, 40],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \n",
    "    # \"perceptron\": {\n",
    "    #     \"max_iter\": [1000, 2000],\n",
    "    #     \"tol\": [1e-3],\n",
    "    #     \"eta0\": [0.001],\n",
    "    #     \"penalty\": [\"l2\"],\n",
    "    #     \"alpha\": [0.0001, 0.001]\n",
    "    # },\n",
    "    \n",
    "    \"perceptron\": {\n",
    "        \"max_iter\": [1000, 2000],\n",
    "        \"tol\": [1e-3, 1e-4],\n",
    "        \"eta0\": [0.001, 0.01, 0.1],\n",
    "        \"penalty\": [None, \"l2\", \"l1\"],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01]\n",
    "    },\n",
    "    \n",
    "    \"mlp\": {\n",
    "        \"hidden_layer_sizes\": [(100,)],\n",
    "        \"activation\": [\"tanh\", \"logistic\"],\n",
    "        \"solver\": [\"sgd\"],\n",
    "        \"alpha\": [0.01],\n",
    "        \"batch_size\": [32],\n",
    "        \"max_iter\": [2000],\n",
    "    },\n",
    "    \n",
    "    # \"mlp\": {\n",
    "    #     \"hidden_layer_sizes\": [(50,), (100,), (50, 50), (100, 100)],\n",
    "    #     \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "    #     \"solver\": [\"adam\", \"sgd\"],\n",
    "    #     \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    #     \"batch_size\": [32, 64, 128],\n",
    "    #     \"max_iter\": [500, 1000],\n",
    "    #     \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "    # },\n",
    "    \n",
    "    \"bayesian\": {\n",
    "        \"priors\": [None, [0.5, 0.5], [0.4, 0.6], [0.3, 0.7], [0.2, 0.8], [0.1, 0.9], [0.05, 0.95]],\n",
    "        \"var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "    },\n",
    "    \n",
    "    \"random_forest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [10],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"bootstrap\": [True, False]\n",
    "    },\n",
    "    \n",
    "    # \"random_forest\": {\n",
    "    #     \"n_estimators\": [50, 100, 200],\n",
    "    #     \"max_depth\": [None, 10, 20, 30],\n",
    "    #     \"min_samples_split\": [2, 5, 10],\n",
    "    #     \"min_samples_leaf\": [1, 2, 4],\n",
    "    #     \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    #     \"bootstrap\": [True, False]\n",
    "    # },\n",
    "    \n",
    "    \"xgboost\": {\n",
    "        \"n_estimators\": [100],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \"max_depth\": [6, 10]\n",
    "    },\n",
    "    \n",
    "    # \"xgboost\": {\n",
    "    #     \"n_estimators\": [100, 200, 300],\n",
    "    #     \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    #     \"max_depth\": [3, 6, 10],\n",
    "    #     \"subsample\": [0.8, 1.0],\n",
    "    #     \"colsample_bytree\": [0.8, 1.0],\n",
    "    #     \"gamma\": [0, 0.1, 0.2]\n",
    "    # },\n",
    "    \n",
    "    \"svm\": {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": [0.001, 0.01, 0.1, 1],\n",
    "        \"gamma\": [0.1, 0.01, \"scale\", \"auto\"]\n",
    "    },\n",
    "    \n",
    "    # \"svm\": {\n",
    "    #     \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    #     \"C\": [0.1, 1, 10, 100],\n",
    "    #     \"gamma\": [0.1, 0.01, \"scale\", \"auto\"],\n",
    "    #     \"degree\": [2, 3, 4]\n",
    "    # },\n",
    "    \n",
    "    # \"logistic_regression\": {\n",
    "    #     \"penalty\": [\"l2\"],\n",
    "    #     \"C\": [0.1, 1.0],\n",
    "    #     \"max_iter\": [1000, 2000]\n",
    "    # },\n",
    "    \n",
    "    \"logistic_regression\": {\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "        \"C\": [0.1, 1.0, 10.0],\n",
    "        \"max_iter\": [1000, 2000]\n",
    "    },\n",
    "    \n",
    "    \n",
    "    # \"hmm\": {\n",
    "    #     \"n_components\": [2],  # Keep it small\n",
    "    #     \"covariance_type\": [\"diag\"],  # Simpler covariance type\n",
    "    #     \"n_iter\": [500],  # Reduce iterations\n",
    "    #     \"init_params\": [\"stmc\"],  # Initialize start probabilities, transition matrix, and means/covariance\n",
    "    #     \"params\": [\"stmc\"]\n",
    "    # },\n",
    "    \n",
    "    \"hmm\": {\n",
    "        \"n_components\": [2, 3, 4],\n",
    "        \"covariance_type\": [\"diag\", \"full\", \"tied\"],\n",
    "        \"n_iter\": [100, 200],\n",
    "        \"init_params\": [\"c\", \"s\", \"cs\"],\n",
    "        \"params\": [\"c\", \"t\", \"ct\"]\n",
    "    },\n",
    "    \n",
    "    \"bayes_network\": {\n",
    "        \"structure\": [None],\n",
    "        \"n_bins\": [2],\n",
    "        \"strategy\": [\"kmeans\"],\n",
    "        \"min_unique_values\": [2],\n",
    "        \"max_features\": [10]\n",
    "    },\n",
    "    \n",
    "    # \"crf\": {\n",
    "    #     \"c1\": [0.1, 0.01],  # L1 Regularization\n",
    "    #     \"c2\": [0.1, 0.01],  # L2 Regularization\n",
    "    #     \"max_iterations\": [50, 100]  # Limit iterations\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Dictionary for dimensionality reduction methods\n",
    "DIMENSIONALITY_REDUCTION_DICT = {\n",
    "    \"pca\": PCA,\n",
    "    \"lda\": LDA,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = os.path.join(project_root, \"data\", \"final\", \"final_clean_no_neutral_no_duplicates_v1.csv\")\n",
    "df = pd.read_csv(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_clean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "      <td>switchfoot awww thats bummer shoulda got david carr third day</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "      <td>upset cant update facebook texting might cry result school today also blah</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "      <td>kenichan dived many times ball managed save  rest go bounds</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "      <td>nationwideclass behaving im mad cant see</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  \\\n",
       "0     0.0   \n",
       "1     0.0   \n",
       "2     0.0   \n",
       "3     0.0   \n",
       "4     0.0   \n",
       "\n",
       "                                                                                                                  text  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D   \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!   \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds   \n",
       "3                                                                      my whole body feels itchy and like its on fire    \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.    \n",
       "\n",
       "                                                                   text_clean  \\\n",
       "0               switchfoot awww thats bummer shoulda got david carr third day   \n",
       "1  upset cant update facebook texting might cry result school today also blah   \n",
       "2                 kenichan dived many times ball managed save  rest go bounds   \n",
       "3                                            whole body feels itchy like fire   \n",
       "4                                    nationwideclass behaving im mad cant see   \n",
       "\n",
       "   text_length  text_clean_length  \n",
       "0           19                 10  \n",
       "1           21                 12  \n",
       "2           18                 10  \n",
       "3           10                  6  \n",
       "4           21                  6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace target 4 with 1\n",
    "df[\"target\"] = df[\"target\"].replace(4, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_methods = [\"tfidf\", \"count\", \"word2vec\", \"glove\"]\n",
    "df_sampled = df.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lst = df_sampled[\"text_clean\"].tolist()\n",
    "label_lst = df_sampled[\"target\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_dict, X_test_features_dict, y_train, y_test = build_vector_for_text(df_sampled, feature_methods, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_lst = [\n",
    "    # \"decision_tree\", # ok\n",
    "    # \"random_forest\", # ok\n",
    "    # \"xgboost\", \n",
    "    # \"perceptron\", # ok\n",
    "    # \"mlp\", # lau but ok\n",
    "    \"lstm\",\n",
    "    # \"bayesian\",\n",
    "    # \"GA\",\n",
    "    # \"hmm\",\n",
    "    # \"bayesnet\",\n",
    "    # \"logistic_regression\",\n",
    "    # \"svm\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = os.path.join(project_root, \"src\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_general_model(df_sampled, doc_lst, label_lst, model_name_lst, feature_methods, MODEL_DICT, MODEL_PARAMS, X_train_features_dict, X_test_features_dict, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_general_model(model_name_lst, feature_methods, X_test_features_dict, y_test, trained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
